{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80985320-d328-4127-8d81-0d61e3850fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74eb00f8-5fdc-436b-ba1a-b8e9507bb5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo\n",
    "import pytorchcv\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29f9dba8-e4da-4307-a08b-033e0e78e29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import itertools\n",
    "import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-v0_8') # pretty matplotlib plots\n",
    "sns.set('notebook', style='whitegrid', font_scale=1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f401bb79-f610-48e7-9d90-e571666ee902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available())\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count())\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_device_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.conda/envs/cs152_env/lib/python3.10/site-packages/torch/cuda/__init__.py:365\u001b[0m, in \u001b[0;36mget_device_name\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_name\u001b[39m(device: Optional[_device_t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    354\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Gets the name of a device.\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \n\u001b[1;32m    356\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m        str: the name of the device\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_device_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m~/.conda/envs/cs152_env/lib/python3.10/site-packages/torch/cuda/__init__.py:395\u001b[0m, in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_properties\u001b[39m(device: _device_t) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _CudaDeviceProperties:\n\u001b[1;32m    386\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Gets the properties of a device.\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;124;03m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 395\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# will define _get_device_properties\u001b[39;00m\n\u001b[1;32m    396\u001b[0m     device \u001b[38;5;241m=\u001b[39m _get_device_index(device, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count():\n",
      "File \u001b[0;32m~/.conda/envs/cs152_env/lib/python3.10/site-packages/torch/cuda/__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfdab05b-5e8c-4e12-8bb8-90ff06a8de92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/joseph280996/Code/School/L3D/Project/l3d_pn_dataset1000\n"
     ]
    }
   ],
   "source": [
    "# device = 'cuda' # TODO change to GPU if you have one (e.g. on Colab)\n",
    "device = 'cpu'\n",
    "# if torch.cuda.is_available():\n",
    "#     device = 'cuda'\n",
    "# else:\n",
    "#     device = 'cpu'\n",
    "\n",
    "host = 'nt'\n",
    "\n",
    "if host == 'hpc':\n",
    "    DATA_DIR = os.environ.get('DATA_DIR', os.path.abspath('/cluster/tufts/cs152l3dclass/jhadid01/l3d_pn_dataset1000'))\n",
    "else:\n",
    "    if os.name == 'nt':\n",
    "        # DATA_DIR = os.environ.get('DATA_DIR', os.path.abspath(\"C:\\\\Users\\\\arman\\\\Downloads\\\\L3D_Project\\\\l3d_pn_dataset1000\"))\n",
    "        DATA_DIR = os.environ.get('DATA_DIR', os.path.abspath(\"C:\\\\Users\\\\arman\\\\Downloads\\\\L3D_Project\\\\l3d_pn_dataset500\"))\n",
    "        # DATA_DIR = os.environ.get('DATA_DIR', os.path.abspath(\"C:\\\\Users\\\\arman\\\\Downloads\\\\L3D_Project\\\\Quotient-train\\\\\"))\n",
    "    else:\n",
    "        DATA_DIR = os.environ.get('DATA_DIR', os.path.abspath('../../l3d_pn_dataset1000'))\n",
    "\n",
    "print(DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c1cc335-870f-4190-ba1e-20f5f1da9fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False_PN  True_PN\n"
     ]
    }
   ],
   "source": [
    "!ls $DATA_DIR/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d04661e-51c0-42d7-8d02-49df2446acd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af076891-a766-46b9-9a80-520148d8950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import utils from provided local starter code files\n",
    "import data_utils\n",
    "import models\n",
    "import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cab1cf85-1e4b-4a81-83e1-12f495720158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_acc(model, device, test_loader):\n",
    "    \"\"\"\n",
    "    Evaluate accuracy of a model on the test loader.\n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        device: 'cuda' or 'cpu'\n",
    "        test_loader: DataLoader for test data\n",
    "\n",
    "    Returns:\n",
    "        Accuracy as a float\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            _, predicted = torch.max(outputs, 1)  # Get predicted class\n",
    "            correct += (predicted == y).sum().item()  # Count correct predictions\n",
    "    return correct / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bafa3ea-683d-4390-9ef6-d833ad42ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_progress(best_infox):\n",
    "    \"\"\"\n",
    "    Plot training and validation progress.\n",
    "    Args:\n",
    "        best_infox: Dictionary containing 'epochs', 'tr' (training), and 'va' (validation) metrics.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Training metrics\n",
    "    plt.plot(best_infox['epochs'], best_infox['tr']['loss'], '--', color='b', label='Training Loss')\n",
    "    plt.plot(best_infox['epochs'], best_infox['tr']['err'], '-', color='b', label='Training Error')\n",
    "\n",
    "    # Validation metrics\n",
    "    plt.plot(best_infox['epochs'], best_infox['va']['xent'], '--', color='r', label='Validation Loss')\n",
    "    plt.plot(best_infox['epochs'], best_infox['va']['err'], '-', color='r', label='Validation Error')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Metrics')\n",
    "    plt.title('Training and Validation Progress')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229b14ec-c1a8-4fa8-8ab6-104363ffad99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitname   0   1\n",
      "    train 100 100\n",
      "    valid  25  25\n",
      "     test 125 125\n",
      "Setup complete. Trainable parameter count=1026 over 2 tensors in layers: output.\n",
      "Setup complete. Trainable parameter count=1026 over 2 tensors in layers: output.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PretrainedResNetForPN' object has no attribute 'fc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 63\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Define your training loop\u001b[39;00m\n\u001b[1;32m     62\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m---> 63\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mResNetFeatureExtractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     64\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m     65\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "Cell \u001b[0;32mIn[22], line 31\u001b[0m, in \u001b[0;36mResNetFeatureExtractor.__init__\u001b[0;34m(self, num_classes)\u001b[0m\n\u001b[1;32m     27\u001b[0m resnet \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mPretrainedResNetForPN(\n\u001b[1;32m     28\u001b[0m     src_dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImageNet1k\u001b[39m\u001b[38;5;124m'\u001b[39m, arch\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResNet10\u001b[39m\u001b[38;5;124m'\u001b[39m, n_trainable_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m\n\u001b[1;32m     29\u001b[0m     )\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_extractor \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(resnet\u001b[38;5;241m.\u001b[39mchildren())[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])  \u001b[38;5;66;03m# Remove FC\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[43mresnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[38;5;241m.\u001b[39min_features, num_classes)\n",
      "File \u001b[0;32m~/.conda/envs/cs152_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PretrainedResNetForPN' object has no attribute 'fc'"
     ]
    }
   ],
   "source": [
    "# Assuming the PNDataset and make_PN_data_loaders are defined as provided\n",
    "root_path = r\"../../l3d_pn_dataset500LP\"\n",
    "\n",
    "# MixMatch hyperparameters\n",
    "mixup_alpha = 0.75\n",
    "temperature = 0.5\n",
    "lambda_u = 75\n",
    "num_classes = 2  # Adjust to your dataset\n",
    "\n",
    "# Define sharpening function\n",
    "def sharpen(probabilities, T):\n",
    "    return torch.pow(probabilities, 1 / T) / torch.sum(torch.pow(probabilities, 1 / T), dim=1, keepdim=True)\n",
    "\n",
    "# Define mixup function\n",
    "def mixup(x1, y1, x2, y2, alpha):\n",
    "    lam = torch.distributions.Beta(alpha, alpha).sample().item()\n",
    "    lam = max(lam, 1 - lam)\n",
    "    x_mix = lam * x1 + (1 - lam) * x2\n",
    "    y_mix = lam * y1 + (1 - lam) * y2\n",
    "    return x_mix, y_mix\n",
    "\n",
    "# ResNet Feature Extractor\n",
    "# class ResNetFeatureExtractor(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super(ResNetFeatureExtractor, self).__init__()\n",
    "#         # Load pre-trained ResNet\n",
    "#         resnet = models.PretrainedResNetForPN(\n",
    "#             src_dataset='ImageNet1k', arch='ResNet10', n_trainable_layers=1, seed=500\n",
    "#             )\n",
    "#         self.feature_extractor = nn.Sequential(*list(resnet.children())[:-1])  # Remove FC\n",
    "#         self.fc = nn.Linear(resnet.fc.in_features, num_classes)  # Custom FC layer\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         features = self.feature_extractor(x)\n",
    "#         features = features.view(features.size(0), -1)  # Flatten\n",
    "#         out = self.fc(features)\n",
    "#         return out\n",
    "\n",
    "# Prepare DataLoaders\n",
    "# root_path = os.path.abspath(\".\")  # Adjust to dataset root\n",
    "tr_loader, va_loader, te_loader = data_utils.make_PN_data_loaders(\n",
    "    root=root_path,\n",
    "    batch_size=32,\n",
    "    n_samples_per_class_trainandvalid=500\n",
    ")\n",
    "\n",
    "# Model, optimizer, and criterion\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = models.PretrainedResNetForPN(\n",
    "            src_dataset='ImageNet1k', arch='ResNet10', n_trainable_layers=1, seed=500\n",
    "    ).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "best_infox = {\n",
    "    'epochs': [],\n",
    "    'tr': {'loss': [], 'err': []},\n",
    "    'va': {'xent': [], 'err': []},\n",
    "}\n",
    "\n",
    "# Define your training loop\n",
    "num_epochs = 50\n",
    "model = models.PretrainedResNetForPN(\n",
    "            src_dataset='ImageNet1k', arch='ResNet10', n_trainable_layers=1, seed=500\n",
    "    ).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    # Training phase\n",
    "    for inputs_x, targets_x in tr_loader:\n",
    "        inputs_x, targets_x = inputs_x.to(device), targets_x.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs_x)\n",
    "        loss = criterion(outputs, targets_x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * inputs_x.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(targets_x).sum().item()\n",
    "        total_samples += inputs_x.size(0)\n",
    "\n",
    "    # Training metrics\n",
    "    train_loss = total_loss / total_samples\n",
    "    train_err = 1 - correct / total_samples\n",
    "    best_infox['tr']['loss'].append(train_loss)\n",
    "    best_infox['tr']['err'].append(train_err)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs_val, targets_val in va_loader:\n",
    "            inputs_val, targets_val = inputs_val.to(device), targets_val.to(device)\n",
    "            outputs_val = model(inputs_val)\n",
    "            loss_val = criterion(outputs_val, targets_val)\n",
    "\n",
    "            val_loss += loss_val.item() * inputs_val.size(0)\n",
    "            _, predicted_val = outputs_val.max(1)\n",
    "            val_correct += predicted_val.eq(targets_val).sum().item()\n",
    "            val_samples += inputs_val.size(0)\n",
    "\n",
    "    # Validation metrics\n",
    "    val_xent = val_loss / val_samples\n",
    "    val_err = 1 - val_correct / val_samples\n",
    "    best_infox['va']['xent'].append(val_xent)\n",
    "    best_infox['va']['err'].append(val_err)\n",
    "\n",
    "    # Track epochs\n",
    "    best_infox['epochs'].append(epoch)\n",
    "\n",
    "    # Logging\n",
    "    print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}, Train Error: {train_err:.4f}\")\n",
    "    print(f\"  Val Loss: {val_xent:.4f}, Val Error: {val_err:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6702ac0a-e19b-4c2e-8812-1417f0dff4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plot_training_progress(best_infox)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_acc = eval_acc(model, device, te_loader)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98b0df0-06cc-45fb-9968-3e3462210e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_acc = {}\n",
    "tar_acc[('ResNet18', 'ImageNet1k')] = eval_acc(model, device, te_loader)\n",
    "print(tar_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fe7470-88b8-42b8-ac95-461c574e1bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3a962d-5871-4122-9cd7-31f37fdd9550",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs152_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
